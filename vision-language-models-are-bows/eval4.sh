# python main_aro.py --dataset winoground --model-name openai-clip:RN50x64
# python main_aro.py --dataset winoground --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset winoground --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset winoground --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset winoground --model-name laion-clip:ViT-g/14

# det command run -w Rohrbach --config-file=config.yaml ". ~/.bashrc; conda activate diffusion-classifier; cd vision-language-models-are-bows; bash eval4.sh" 

# python main_aro.py --dataset spec_existence --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_existence --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_existence --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_existence --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_existence --model-name laion-clip:ViT-g/14


# python main_aro.py --dataset spec_absolute_size --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_absolute_size --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_absolute_size --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_absolute_size --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_absolute_size --model-name laion-clip:ViT-g/14



# python main_aro.py --dataset eqbench_eqbenkubric_attr --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset eqbench_eqbenkubric_attr --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset eqbench_eqbenkubric_attr --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset eqbench_eqbenkubric_cnt --model-name openai-clip:RN50x64
# python main_aro.py --dataset eqbench_eqbenkubric_cnt --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset eqbench_eqbenkubric_cnt --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset eqbench_eqbenkubric_cnt --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset eqbench_eqbenkubric_cnt --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name openai-clip:RN50x64
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset eqbench_eqbensd --model-name openai-clip:RN50x64
# python main_aro.py --dataset eqbench_eqbensd --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset eqbench_eqbensd --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset eqbench_eqbensd --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset eqbench_eqbensd --model-name laion-clip:ViT-g/14
