# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name openai-clip:RN50x64
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset eqbench_eqbenkubric_loc --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset spec_absolute_spatial_img_retrieval --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_absolute_spatial_img_retrieval --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_absolute_spatial_img_retrieval --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_absolute_spatial_img_retrieval --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_absolute_spatial_img_retrieval --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset spec_relative_spatial_img_retrieval --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_relative_spatial_img_retrieval --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_relative_spatial_img_retrieval --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_relative_spatial_img_retrieval --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_relative_spatial_img_retrieval --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset spec_relative_size_img_retrieval --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_relative_size_img_retrieval --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_relative_size_img_retrieval --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_relative_size_img_retrieval --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_relative_size_img_retrieval --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset spec_existence_img_retrieval --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_existence_img_retrieval --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_existence_img_retrieval --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_existence_img_retrieval --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_existence_img_retrieval --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset spec_count_img_retrieval --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_count_img_retrieval --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_count_img_retrieval --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_count_img_retrieval --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_count_img_retrieval --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset spec_absolute_size_img_retrieval --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_absolute_size_img_retrieval --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_absolute_size_img_retrieval --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_absolute_size_img_retrieval --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_absolute_size_img_retrieval --model-name laion-clip:ViT-g/14


# python main_aro.py --dataset geneval_color --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0

# python main_aro.py --dataset geneval_color --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_color_attr --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_position --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_counting --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_single --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0
# python main_aro.py --dataset geneval_two --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0



# python main_aro.py --dataset mmvp_camera --model-name openai-clip:RN50x64
# python main_aro.py --dataset mmvp_color --model-name openai-clip:RN50x64
# python main_aro.py --dataset mmvp_orientation --model-name openai-clip:RN50x64
# python main_aro.py --dataset mmvp_presence --model-name openai-clip:RN50x64
# python main_aro.py --dataset mmvp_quantity --model-name openai-clip:RN50x64
# python main_aro.py --dataset mmvp_state --model-name openai-clip:RN50x64
# python main_aro.py --dataset mmvp_structural --model-name openai-clip:RN50x64
# python main_aro.py --dataset mmvp_text --model-name openai-clip:RN50x64

# python main_aro.py --dataset mmvp_camera --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_color --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_orientation --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_spatial --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_presence --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_quantity --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_state --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_structural --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset mmvp_text --model-name openai-clip:ViT-L/14

# python main_aro.py --dataset mmvp_camera --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset mmvp_color --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset mmvp_orientation --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset mmvp_presence --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset mmvp_quantity --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset mmvp_state --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset mmvp_structural --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset mmvp_text --model-name openai-clip:ViT-B/32


# python main_aro.py --dataset mmvp_camera --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset mmvp_color --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset mmvp_orientation --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset mmvp_presence --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset mmvp_quantity --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset mmvp_state --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset mmvp_structural --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset mmvp_text --model-name laion-clip:ViT-H/14

# python main_aro.py --dataset mmvp_camera --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset mmvp_color --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset mmvp_orientation --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset mmvp_presence --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset mmvp_quantity --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset mmvp_state --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset mmvp_structural --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset mmvp_text --model-name laion-clip:ViT-g/14
# python main_aro.py --dataset ours_1_5_colors --model-name openai-clip:RN50x64


# python main_aro.py --dataset vismin_relation --model-name openai-clip:RN50x64
# python main_aro.py --dataset valse_action-replacement --model-name openai-clip:RN50x64
# python main_aro.py --dataset eqbench_eqbenyoucook2 --model-name openai-clip:RN50x64
# python main_aro.py --dataset eqbench_eqbenag --model-name openai-clip:RN50x64
# python main_aro.py --dataset eqbench_eqbengebc --model-name openai-clip:RN50x64
# python main_aro.py --dataset vlcheck_action --model-name openai-clip:RN50x64
# python main_aro.py --dataset vlcheck_Relation_vg_spatial --model-name openai-clip:RN50x64
# python main_aro.py --dataset vlcheck_Relation_vg_action --model-name openai-clip:RN50x64

# python main_aro.py --dataset vlcheck_Object_Location_hake --model-name openai-clip:RN50x64

# "A scene with seven balloons, Bounding boxes:  [('a balloon', [40, 150, 80, 120]), ('a balloon', [140, 150, 80, 120]), ('a balloon', [240, 150, 80, 120]), ('a balloon', [340, 150, 80, 120]), ('a balloon', [50, 50, 80, 120]), ('a balloon', [150, 50, 80, 120]), ('a balloon', [250, 50, 80, 120])], Background prompt: A children's party, Negative prompt: No adults., Category: counting(seven)"

# python main_aro.py --dataset ours_colors --model-name openai-clip:RN50x64 --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:RN50x64 --version 1.5
# python main_aro.py --dataset ours_position --model-name openai-clip:RN50x64 --version 1.5
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:RN50x64 --version 1.5

# python main_aro.py --dataset ours_before_colors --model-name openai-clip:RN50x64 --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:RN50x64 --version 1.5
# python main_aro.py --dataset ours_before_position --model-name openai-clip:RN50x64 --version 1.5
# python main_aro.py --dataset ours_counting --model-name openai-clip:RN50x64 --version 1.5

# python main_aro.py --dataset ours_colors --model-name openai-clip:RN50x64 --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:RN50x64 --version 2.0
# python main_aro.py --dataset ours_position --model-name openai-clip:RN50x64 --version 2.0
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:RN50x64 --version 2.0
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:RN50x64 --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:RN50x64 --version 2.0
# python main_aro.py --dataset ours_before_position --model-name openai-clip:RN50x64 --version 2.0
# python main_aro.py --dataset ours_counting --model-name openai-clip:RN50x64 --version 2.0

# python main_aro.py --dataset ours_colors --model-name openai-clip:RN50x64 --version 3-m
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:RN50x64 --version 3-m
# python main_aro.py --dataset ours_position --model-name openai-clip:RN50x64 --version 3-m
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:RN50x64 --version 3-m
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:RN50x64 --version 3-m
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:RN50x64 --version 3-m
# python main_aro.py --dataset ours_before_position --model-name openai-clip:RN50x64 --version 3-m
# python main_aro.py --dataset ours_counting --model-name openai-clip:RN50x64 --version 3-m

# python main_aro.py --dataset ours_colors --model-name openai-clip:ViT-L/14 --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-L/14 --version 1.5
# python main_aro.py --dataset ours_position --model-name openai-clip:ViT-L/14 --version 1.5
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:ViT-L/14 --version 1.5
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:ViT-L/14 --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-L/14 --version 1.5
# python main_aro.py --dataset ours_before_position --model-name openai-clip:ViT-L/14 --version 1.5
# python main_aro.py --dataset ours_counting --model-name openai-clip:ViT-L/14 --version 1.5

# python main_aro.py --dataset ours_colors --model-name openai-clip:ViT-L/14 --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-L/14 --version 2.0
# python main_aro.py --dataset ours_position --model-name openai-clip:ViT-L/14 --version 2.0
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:ViT-L/14 --version 2.0
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:ViT-L/14 --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-L/14 --version 2.0
# python main_aro.py --dataset ours_before_position --model-name openai-clip:ViT-L/14 --version 2.0
# python main_aro.py --dataset ours_counting --model-name openai-clip:ViT-L/14 --version 2.0

# python main_aro.py --dataset ours_colors --model-name openai-clip:ViT-L/14 --version 3-m
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-L/14 --version 3-m
# python main_aro.py --dataset ours_position --model-name openai-clip:ViT-L/14 --version 3-m
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:ViT-L/14 --version 3-m
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:ViT-L/14 --version 3-m
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-L/14 --version 3-m
# python main_aro.py --dataset ours_before_position --model-name openai-clip:ViT-L/14 --version 3-m
# python main_aro.py --dataset ours_counting --model-name openai-clip:ViT-L/14 --version 3-m

# python main_aro.py --dataset ours_colors --model-name openai-clip:ViT-B/32 --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-B/32 --version 1.5
# python main_aro.py --dataset ours_position --model-name openai-clip:ViT-B/32 --version 1.5
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:ViT-B/32 --version 1.5
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:ViT-B/32 --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-B/32 --version 1.5
# python main_aro.py --dataset ours_before_position --model-name openai-clip:ViT-B/32 --version 1.5
# python main_aro.py --dataset ours_counting --model-name openai-clip:ViT-B/32 --version 1.5

# python main_aro.py --dataset ours_colors --model-name openai-clip:ViT-B/32 --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-B/32 --version 2.0
# python main_aro.py --dataset ours_position --model-name openai-clip:ViT-B/32 --version 2.0
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:ViT-B/32 --version 2.0
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:ViT-B/32 --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-B/32 --version 2.0
# python main_aro.py --dataset ours_before_position --model-name openai-clip:ViT-B/32 --version 2.0
# python main_aro.py --dataset ours_counting --model-name openai-clip:ViT-B/32 --version 2.0

# python main_aro.py --dataset ours_colors --model-name openai-clip:ViT-B/32 --version 3-m
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-B/32 --version 3-m
# python main_aro.py --dataset ours_position --model-name openai-clip:ViT-B/32 --version 3-m
# python main_aro.py --dataset ours_before_counting --model-name openai-clip:ViT-B/32 --version 3-m
# python main_aro.py --dataset ours_before_colors --model-name openai-clip:ViT-B/32 --version 3-m
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-B/32 --version 3-m
# python main_aro.py --dataset ours_before_position --model-name openai-clip:ViT-B/32 --version 3-m
# python main_aro.py --dataset ours_counting --model-name openai-clip:ViT-B/32 --version 3-m

# python main_aro.py --dataset ours_colors --model-name laion-clip:ViT-H/14 --version 3-m
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-H/14 --version 3-m
# python main_aro.py --dataset ours_position --model-name laion-clip:ViT-H/14 --version 3-m
# python main_aro.py --dataset ours_before_counting --model-name laion-clip:ViT-H/14 --version 3-m
# python main_aro.py --dataset ours_before_colors --model-name laion-clip:ViT-H/14 --version 3-m
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-H/14 --version 3-m
# python main_aro.py --dataset ours_before_position --model-name laion-clip:ViT-H/14 --version 3-m
# python main_aro.py --dataset ours_counting --model-name laion-clip:ViT-H/14 --version 3-m

# python main_aro.py --dataset ours_colors --model-name laion-clip:ViT-H/14 --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-H/14 --version 2.0
# python main_aro.py --dataset ours_position --model-name laion-clip:ViT-H/14 --version 2.0
# python main_aro.py --dataset ours_before_counting --model-name laion-clip:ViT-H/14 --version 2.0
# python main_aro.py --dataset ours_before_colors --model-name laion-clip:ViT-H/14 --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-H/14 --version 2.0
# python main_aro.py --dataset ours_before_position --model-name laion-clip:ViT-H/14 --version 2.0
# python main_aro.py --dataset ours_counting --model-name laion-clip:ViT-H/14 --version 2.0

# python main_aro.py --dataset ours_colors --model-name laion-clip:ViT-H/14 --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-H/14 --version 1.5
# python main_aro.py --dataset ours_position --model-name laion-clip:ViT-H/14 --version 1.5
# python main_aro.py --dataset ours_before_counting --model-name laion-clip:ViT-H/14 --version 1.5
# python main_aro.py --dataset ours_before_colors --model-name laion-clip:ViT-H/14 --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-H/14 --version 1.5
# python main_aro.py --dataset ours_before_position --model-name laion-clip:ViT-H/14 --version 1.5
# python main_aro.py --dataset ours_counting --model-name laion-clip:ViT-H/14 --version 1.5

# python main_aro.py --dataset ours_colors --model-name laion-clip:ViT-g/14 --version 3-m
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-g/14 --version 3-m
# python main_aro.py --dataset ours_position --model-name laion-clip:ViT-g/14 --version 3-m
# python main_aro.py --dataset ours_before_counting --model-name laion-clip:ViT-g/14 --version 3-m
# python main_aro.py --dataset ours_before_colors --model-name laion-clip:ViT-g/14 --version 3-m
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-g/14 --version 3-m
# python main_aro.py --dataset ours_before_position --model-name laion-clip:ViT-g/14 --version 3-m
# python main_aro.py --dataset ours_counting --model-name laion-clip:ViT-g/14 --version 3-m

# python main_aro.py --dataset ours_colors --model-name laion-clip:ViT-g/14 --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-g/14 --version 2.0
# python main_aro.py --dataset ours_position --model-name laion-clip:ViT-g/14 --version 2.0
# python main_aro.py --dataset ours_before_counting --model-name laion-clip:ViT-g/14 --version 2.0
# python main_aro.py --dataset ours_before_colors --model-name laion-clip:ViT-g/14 --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-g/14 --version 2.0
# python main_aro.py --dataset ours_before_position --model-name laion-clip:ViT-g/14 --version 2.0
# python main_aro.py --dataset ours_counting --model-name laion-clip:ViT-g/14 --version 2.0

# python main_aro.py --dataset ours_colors --model-name laion-clip:ViT-g/14 --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-g/14 --version 1.5
# python main_aro.py --dataset ours_position --model-name laion-clip:ViT-g/14 --version 1.5
# python main_aro.py --dataset ours_before_counting --model-name laion-clip:ViT-g/14 --version 1.5
# python main_aro.py --dataset ours_before_colors --model-name laion-clip:ViT-g/14 --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-g/14 --version 1.5
# python main_aro.py --dataset ours_before_position --model-name laion-clip:ViT-g/14 --version 1.5
# python main_aro.py --dataset ours_counting --model-name laion-clip:ViT-g/14 --version 1.5

# python main_aro.py --dataset VG_Relation --model-name openai-clip:RN50x64
# python main_aro.py --dataset VG_Relation --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset VG_Relation --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset VG_Relation --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset VG_Relation --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset VG_Attribution --model-name openai-clip:RN50x64
# python main_aro.py --dataset VG_Attribution --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset VG_Attribution --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset VG_Attribution --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset VG_Attribution --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset COCO_Order --model-name openai-clip:RN50x64
# python main_aro.py --dataset COCO_Order --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset COCO_Order --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset COCO_Order --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset COCO_Order --model-name laion-clip:ViT-g/14


# python main_aro.py --dataset spec_absolute_spatial --model-name openai-clip:RN50x64
# python main_aro.py --dataset spec_absolute_spatial --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset spec_absolute_spatial --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset spec_absolute_spatial --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset spec_absolute_spatial --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset vismin_counting --model-name openai-clip:RN50x64
# python main_aro.py --dataset vismin_counting --model-name openai-clip:ViT-L/14
# python main_aro.py --dataset vismin_counting --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset vismin_counting --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset vismin_counting --model-name laion-clip:ViT-g/14

# python main_aro.py --dataset vismin_object --model-name openai-clip:RN50x64
# python main_aro.py --dataset vismin_object --model-name openai-clip:ViT-L/14    
# python main_aro.py --dataset vismin_object --model-name openai-clip:ViT-B/32
# python main_aro.py --dataset vismin_object --model-name laion-clip:ViT-H/14
# python main_aro.py --dataset vismin_object --model-name laion-clip:ViT-g/14


# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-H/14  --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-H/14  --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-H/14  --version 3-m

# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-L/14  --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-L/14  --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-L/14  --version 3-m

# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-B/32  --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-B/32  --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:ViT-B/32  --version 3-m

# python main_aro.py --dataset ours_color_attr --model-name openai-clip:RN50x64  --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:RN50x64  --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name openai-clip:RN50x64  --version 3-m

# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-g/14  --version 1.5
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-g/14  --version 2.0
# python main_aro.py --dataset ours_color_attr --model-name laion-clip:ViT-g/14  --version 3-m

# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-g/14  --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-g/14  --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-g/14  --version 3-m

# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-H/14  --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-H/14  --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name laion-clip:ViT-H/14  --version 3-m

# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-L/14  --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-L/14  --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-L/14  --version 3-m

# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-B/32  --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-B/32  --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:ViT-B/32  --version 3-m

# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:RN50x64  --version 1.5
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:RN50x64  --version 2.0
# python main_aro.py --dataset ours_before_color_attr --model-name openai-clip:RN50x64  --version 3-m

# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_two_subset --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_two_subset --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_two_subset --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:RN50x64 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:RN50x64 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:RN50x64 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:ViT-L/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:ViT-L/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:ViT-L/14 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:ViT-B/32 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:ViT-B/32 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name openai-clip:ViT-B/32 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_filter_two_subset --model-name laion-clip:ViT-H/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name laion-clip:ViT-H/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name laion-clip:ViT-H/14 --version 3-m --cfg 9.0

# python main_aro.py --dataset geneval_filter_two_subset --model-name laion-clip:ViT-g/14 --version 1.5 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name laion-clip:ViT-g/14 --version 2.0 --cfg 9.0
# python main_aro.py --dataset geneval_filter_two_subset --model-name laion-clip:ViT-g/14 --version 3-m --cfg 9.0


